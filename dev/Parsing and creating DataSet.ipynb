{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf52eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-12-30 18:13:26 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from os import mkdir\n",
    "from os.path import isdir, isfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e879a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in c:\\users\\265375\\anaconda3\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: ipython in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython-autotime) (7.31.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (5.7.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (65.5.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: pygments in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (2.11.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\265375\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.4.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\265375\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\265375\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n",
      "time: 0 ns (started: 2022-12-30 18:12:10 +03:00)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af2b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "time: 515 ms (started: 2022-12-30 18:12:10 +03:00)\n"
     ]
    }
   ],
   "source": [
    "URL_TEMPLATE = \"https://amulex.ru/docs/\"\n",
    "docs = requests.get(URL_TEMPLATE, headers={'User-Agent': 'Custom'})\n",
    "print(docs.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(docs.text, \"html.parser\")\n",
    "category_contract_url = soup.find_all('a',\n",
    "                                      class_='category__item-link')\n",
    "folder_names = ['Договоры аренды','Договоры купли-продажи','Договоры оказания услуг','Договоры подряда','Договоры поставки']\n",
    "folder_path = 'C:/Users/265375/Desktop/Work/parsing/'\n",
    "os.chdir(folder_path)\n",
    "for j in range(len(category_contract_url)):\n",
    "    s=category_contract_url[j].h2.text\n",
    "    re.sub(r\"\\s+\", \"\", s)\n",
    "    if 'аренд' in s:\n",
    "        category_cite = requests.get('https://amulex.ru'+category_contract_url[j]['href'], headers={'User-Agent': 'Custom'})\n",
    "        categ = bs(category_cite.text, \"html.parser\")\n",
    "        contract_url = categ.find_all('li',class_='items__item',id = False)\n",
    "        contract_names = categ.find_all('h5',class_=\"items__item-title\")\n",
    "        os.makedirs(folder_names[0], exist_ok=True)\n",
    "        for i in range(len(contract_url)):\n",
    "            name_words = contract_names[i].text.split()\n",
    "            name = ''\n",
    "            for k in name_words:\n",
    "                name += ''.join(e for e in k if e.isalnum())\n",
    "                if k != name_words[-1]:\n",
    "                    name += '_'\n",
    "            contract_cite = requests.get('https://amulex.ru'+contract_url[i].a['href'], headers={'User-Agent': 'Custom'})\n",
    "            pars = bs(contract_cite.text, \"html.parser\")\n",
    "            contract_download_url = pars.find('div',class_='download__dropdown js-dropdown')\n",
    "            x = requests.get(contract_download_url.a['href'])\n",
    "            if isfile(folder_path+folder_names[0]+'/'+name+'.pdf')==False:\n",
    "                with open(folder_path+folder_names[0]+'/'+name+'.pdf', 'wb') as f:\n",
    "                    f.write(x.content)\n",
    "    elif 'купл' in s:\n",
    "        category_cite = requests.get('https://amulex.ru'+category_contract_url[j]['href'], headers={'User-Agent': 'Custom'})\n",
    "        categ = bs(category_cite.text, \"html.parser\")\n",
    "        contract_url = categ.find_all('li',class_='items__item',id = False)\n",
    "        contract_names = categ.find_all('h5',class_=\"items__item-title\")\n",
    "        os.makedirs(folder_names[1], exist_ok=True)\n",
    "        for i in range(len(contract_url)):\n",
    "            name_words = contract_names[i].text.split()\n",
    "            name = ''\n",
    "            for k in name_words:\n",
    "                name += ''.join(e for e in k if e.isalnum())\n",
    "                if k != name_words[-1]:\n",
    "                    name += '_'\n",
    "            contract_cite = requests.get('https://amulex.ru'+contract_url[i].a['href'], headers={'User-Agent': 'Custom'})\n",
    "            pars = bs(contract_cite.text, \"html.parser\")\n",
    "            contract_download_url = pars.find('div',class_='download__dropdown js-dropdown')\n",
    "            x = requests.get(contract_download_url.a['href'])\n",
    "            if isfile(folder_path+folder_names[1]+'/'+name+'.pdf')==False:\n",
    "                with open(folder_path+folder_names[1]+'/'+name+'.pdf', 'wb') as f:\n",
    "                    f.write(x.content)\n",
    "    elif 'услуг' in s:\n",
    "        category_cite = requests.get('https://amulex.ru'+category_contract_url[j]['href'], headers={'User-Agent': 'Custom'})\n",
    "        categ = bs(category_cite.text, \"html.parser\")\n",
    "        contract_url = categ.find_all('li',class_='items__item',id = False)\n",
    "        contract_names = categ.find_all('h5',class_=\"items__item-title\")\n",
    "        os.makedirs(folder_names[2], exist_ok=True)\n",
    "        for i in range(len(contract_url)):\n",
    "            name_words = contract_names[i].text.split()\n",
    "            name = ''\n",
    "            for k in name_words:\n",
    "                name += ''.join(e for e in k if e.isalnum())\n",
    "                if k != name_words[-1]:\n",
    "                    name += '_'\n",
    "            contract_cite = requests.get('https://amulex.ru'+contract_url[i].a['href'], headers={'User-Agent': 'Custom'})\n",
    "            pars = bs(contract_cite.text, \"html.parser\")\n",
    "            contract_download_url = pars.find('div',class_='download__dropdown js-dropdown')\n",
    "            x = requests.get(contract_download_url.a['href'])\n",
    "            if isfile(folder_path+folder_names[2]+'/'+name+'.pdf')==False:\n",
    "                with open(folder_path+folder_names[2]+'/'+name+'.pdf', 'wb') as f:\n",
    "                    f.write(x.content)\n",
    "    elif 'подряд' in s:\n",
    "        category_cite = requests.get('https://amulex.ru'+category_contract_url[j]['href'], headers={'User-Agent': 'Custom'})\n",
    "        categ = bs(category_cite.text, \"html.parser\")\n",
    "        contract_url = categ.find_all('li',class_='items__item',id = False)\n",
    "        contract_names = categ.find_all('h5',class_=\"items__item-title\")\n",
    "        os.makedirs(folder_names[3], exist_ok=True)\n",
    "        for i in range(len(contract_url)):\n",
    "            name_words = contract_names[i].text.split()\n",
    "            name = ''\n",
    "            for k in name_words:\n",
    "                name += ''.join(e for e in k if e.isalnum())\n",
    "                if k != name_words[-1]:\n",
    "                    name += '_'\n",
    "            contract_cite = requests.get('https://amulex.ru'+contract_url[i].a['href'], headers={'User-Agent': 'Custom'})\n",
    "            pars = bs(contract_cite.text, \"html.parser\")\n",
    "            contract_download_url = pars.find('div',class_='download__dropdown js-dropdown')\n",
    "            x = requests.get(contract_download_url.a['href'])\n",
    "            if isfile(folder_path+folder_names[3]+'/'+name+'.pdf')==False:\n",
    "                with open(folder_path+folder_names[3]+'/'+name+'.pdf', 'wb') as f:\n",
    "                    f.write(x.content)\n",
    "    elif 'постав' in s:\n",
    "        category_cite = requests.get('https://amulex.ru'+category_contract_url[j]['href'], headers={'User-Agent': 'Custom'})\n",
    "        categ = bs(category_cite.text, \"html.parser\")\n",
    "        contract_url = categ.find_all('li',class_='items__item',id = False)\n",
    "        contract_names = categ.find_all('h5',class_=\"items__item-title\")\n",
    "        os.makedirs(folder_names[4], exist_ok=True)\n",
    "        for i in range(len(contract_url)):\n",
    "            name_words = contract_names[i].text.split()\n",
    "            name = ''\n",
    "            for k in name_words:\n",
    "                name += ''.join(e for e in k if e.isalnum())\n",
    "                if k != name_words[-1]:\n",
    "                    name += '_'\n",
    "            contract_cite = requests.get('https://amulex.ru'+contract_url[i].a['href'], headers={'User-Agent': 'Custom'})\n",
    "            pars = bs(contract_cite.text, \"html.parser\")\n",
    "            contract_download_url = pars.find('div',class_='download__dropdown js-dropdown')\n",
    "            x = requests.get(contract_download_url.a['href'])\n",
    "            if isfile(folder_path+folder_names[4]+'/'+name+'.pdf')==False:\n",
    "                with open(folder_path+folder_names[4]+'/'+name+'.pdf', 'wb') as f:\n",
    "                    f.write(x.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ec457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\265375\\anaconda3\\lib\\site-packages (1.21.0)\n",
      "time: 3.81 s (started: 2022-12-30 18:13:32 +03:00)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0514a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.8 s (started: 2022-12-30 18:14:19 +03:00)\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/265375/Desktop/Work/parsing/'\n",
    "docs = pd.DataFrame(columns = ['text','filename','target'])\n",
    "count = 0\n",
    "\n",
    "for fold_name in folder_names:\n",
    "    folder_path = os.chdir('C:/Users/265375/Desktop/Work/parsing/'+fold_name)\n",
    "    for name in os.listdir(folder_path):\n",
    "        doc = fitz.open(name)\n",
    "        text = ''\n",
    "        for current_page in range(doc.page_count):\n",
    "            text += doc.get_page_text(current_page,\"text\")\n",
    "        text = '\\n'.join(text.split('\\n')[::2])\n",
    "        new_row = {'text':text,'filename':name,'target':fold_name}\n",
    "        docs = docs.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a854b3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 312 ms (started: 2022-12-30 18:14:53 +03:00)\n"
     ]
    }
   ],
   "source": [
    "docs.to_csv('C:/Users/265375/Desktop/Work/parsing/parsed_data.csv', sep='\\t',index=False, encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
